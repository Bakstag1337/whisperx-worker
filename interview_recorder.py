#!/usr/bin/env python3
"""
Ð—Ð°Ð¿Ð¸ÑÑŒ ÑÐ¾Ð±ÐµÑÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ð¹ Ñ GUI, VU-Ð¼ÐµÑ‚Ñ€Ð¾Ð¼ Ð¸ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸ÐµÐ¹.

Ð—Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸:
    sudo apt install ffmpeg python3-tk
    pipx install openai-whisper

Ð—Ð°Ð¿ÑƒÑÐº:
    python3 interview_recorder.py
"""

import subprocess
import signal
import time
import threading
import struct
import os
import base64
import json
import requests
from datetime import datetime
from pathlib import Path
import tkinter as tk
from tkinter import ttk, messagebox, filedialog


class AudioMeter:
    """Ð§Ð¸Ñ‚Ð°ÐµÑ‚ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ Ð·Ð²ÑƒÐºÐ° Ð¸Ð· PulseAudio."""
    
    def __init__(self, callback):
        self.callback = callback
        self.running = False
        self.process = None
        self.thread = None
        
    def start(self):
        self.running = True
        self.thread = threading.Thread(target=self._read_audio, daemon=True)
        self.thread.start()
        
    def stop(self):
        self.running = False
        if self.process:
            self.process.terminate()
            self.process = None
            
    def _read_audio(self):
        try:
            sink = subprocess.run(
                ["pactl", "get-default-sink"],
                capture_output=True, text=True
            ).stdout.strip()
            
            cmd = [
                "ffmpeg",
                "-f", "pulse", "-i", f"{sink}.monitor",
                "-f", "pulse", "-i", "default",
                "-filter_complex", "amix=inputs=2:duration=longest",
                "-f", "s16le",
                "-ac", "1",
                "-ar", "8000",
                "-"
            ]
            
            self.process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.DEVNULL
            )
            
            chunk_size = 800
            
            while self.running and self.process:
                data = self.process.stdout.read(chunk_size * 2)
                if not data:
                    break
                    
                samples = struct.unpack(f"{len(data)//2}h", data)
                if samples:
                    rms = (sum(s*s for s in samples) / len(samples)) ** 0.5
                    level = min(100, int(rms / 327.67))
                    self.callback(level)
                    
        except Exception as e:
            print(f"[Meter] Error: {e}")


class InterviewRecorder:
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("ðŸŽ™ Interview Recorder")
        self.root.geometry("450x450")
        self.root.resizable(False, False)

        self.recording = False
        self.process = None
        self.start_time = None
        self.output_file = None
        self.meter = None
        self.transcribing = False

        # Server transcription settings
        self.runpod_endpoint = "https://api.runpod.ai/v2/yawnskk7m78v7w/run"

        self.setup_ui()
        self.check_dependencies()

        print("=" * 50)
        print("ðŸŽ™  Interview Recorder")
        print("=" * 50)
        
    def setup_ui(self):
        main = ttk.Frame(self.root, padding=20)
        main.pack(fill=tk.BOTH, expand=True)
        
        # Ð¡Ñ‚Ð°Ñ‚ÑƒÑ
        self.status_var = tk.StringVar(value="Ð“Ð¾Ñ‚Ð¾Ð² Ðº Ð·Ð°Ð¿Ð¸ÑÐ¸")
        ttk.Label(main, textvariable=self.status_var, font=("", 11)).pack(pady=(0, 5))
        
        # Ð¢Ð°Ð¹Ð¼ÐµÑ€
        self.timer_var = tk.StringVar(value="00:00:00")
        ttk.Label(main, textvariable=self.timer_var, font=("Monospace", 28, "bold")).pack(pady=(0, 10))
        
        # VU-Ð¼ÐµÑ‚Ñ€
        meter_frame = ttk.Frame(main)
        meter_frame.pack(fill=tk.X, pady=(0, 5))
        
        ttk.Label(meter_frame, text="ðŸŽ¤", font=("", 14)).pack(side=tk.LEFT)
        
        self.meter_canvas = tk.Canvas(meter_frame, height=20, bg="#2a2a2a", highlightthickness=0)
        self.meter_canvas.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(5, 0))
        
        self.meter_level = 0
        self.draw_meter()
        
        # ÐžÐ¿Ñ†Ð¸Ð¸
        options_frame = ttk.LabelFrame(main, text="ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸", padding=10)
        options_frame.pack(fill=tk.X, pady=(0, 15))
        
        # Ð¯Ð·Ñ‹Ðº Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
        lang_frame = ttk.Frame(options_frame)
        lang_frame.pack(fill=tk.X, pady=(0, 5))
        
        ttk.Label(lang_frame, text="Ð¯Ð·Ñ‹Ðº:").pack(side=tk.LEFT)
        self.language_var = tk.StringVar(value="ru")
        lang_combo = ttk.Combobox(
            lang_frame, 
            textvariable=self.language_var,
            values=["ru", "en"],
            state="readonly",
            width=5
        )
        lang_combo.pack(side=tk.LEFT, padx=(10, 0))
        
        ttk.Label(lang_frame, text="ÐœÐ¾Ð´ÐµÐ»ÑŒ:").pack(side=tk.LEFT, padx=(20, 0))
        self.model_var = tk.StringVar(value="base")
        model_combo = ttk.Combobox(
            lang_frame,
            textvariable=self.model_var,
            values=["tiny", "base", "small", "medium", "turbo"],
            state="readonly",
            width=8
        )
        model_combo.pack(side=tk.LEFT, padx=(10, 0))
        
        # Ð§ÐµÐºÐ±Ð¾ÐºÑÑ‹
        self.transcribe_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(
            options_frame,
            text="Ð¢Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð±Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ (Whisper)",
            variable=self.transcribe_var
        ).pack(anchor=tk.W)

        self.keep_audio_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(
            options_frame,
            text="Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð°ÑƒÐ´Ð¸Ð¾ (MP3, ~20 MB/Ñ‡Ð°Ñ)",
            variable=self.keep_audio_var
        ).pack(anchor=tk.W)

        self.use_server_var = tk.BooleanVar(value=False)
        ttk.Checkbutton(
            options_frame,
            text="â˜ï¸ Ð¢Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð±Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€Ðµ (WhisperX + Ð´Ð¸Ð°Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ñ)",
            variable=self.use_server_var
        ).pack(anchor=tk.W, pady=(5, 0))
        
        # ÐšÐ½Ð¾Ð¿ÐºÐ¸ Ð·Ð°Ð¿Ð¸ÑÐ¸
        btn_frame = ttk.Frame(main)
        btn_frame.pack(fill=tk.X, pady=(0, 10))
        
        self.record_btn = ttk.Button(
            btn_frame, 
            text="âº ÐÐ°Ñ‡Ð°Ñ‚ÑŒ Ð·Ð°Ð¿Ð¸ÑÑŒ", 
            command=self.toggle_recording
        )
        self.record_btn.pack(side=tk.LEFT, expand=True, fill=tk.X, padx=(0, 5))
        
        ttk.Button(
            btn_frame,
            text="ðŸ“",
            width=3,
            command=self.open_folder
        ).pack(side=tk.RIGHT)
        
        # ÐšÐ½Ð¾Ð¿ÐºÐ° Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ð¸ Ñ„Ð°Ð¹Ð»Ð°
        self.transcribe_file_btn = ttk.Button(
            main,
            text="ðŸ“„ Ð¢Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð±Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ„Ð°Ð¹Ð»...",
            command=self.transcribe_existing_file
        )
        self.transcribe_file_btn.pack(fill=tk.X)
        
        # Ð˜Ð½Ñ„Ð¾ Ð¾ Ñ„Ð°Ð¹Ð»Ðµ
        self.file_var = tk.StringVar(value="")
        ttk.Label(main, textvariable=self.file_var, font=("", 9), foreground="gray").pack(pady=(15, 0))
        
    def draw_meter(self):
        self.meter_canvas.delete("all")
        width = self.meter_canvas.winfo_width() or 100
        height = 20
        
        self.meter_canvas.create_rectangle(0, 0, width, height, fill="#2a2a2a", outline="")
        
        if self.meter_level > 0:
            level_width = int(width * self.meter_level / 100)
            
            if self.meter_level < 50:
                color = "#4CAF50"
            elif self.meter_level < 80:
                color = "#FFC107"
            else:
                color = "#F44336"
                
            self.meter_canvas.create_rectangle(0, 0, level_width, height, fill=color, outline="")
        
        for i in range(1, 5):
            x = width * i / 5
            self.meter_canvas.create_line(x, 0, x, height, fill="#555", width=1)
            
    def update_meter(self, level):
        self.meter_level = level
        self.root.after(0, self.draw_meter)
        
    def check_dependencies(self):
        try:
            subprocess.run(["ffmpeg", "-version"], capture_output=True, check=True)
        except FileNotFoundError:
            messagebox.showerror("ÐžÑˆÐ¸Ð±ÐºÐ°", "ffmpeg Ð½Ðµ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½!\n\nsudo apt install ffmpeg")
            self.root.quit()
            
    def get_default_sink(self):
        result = subprocess.run(["pactl", "get-default-sink"], capture_output=True, text=True)
        return result.stdout.strip()
    
    def toggle_recording(self):
        if self.recording:
            self.stop_recording()
        else:
            self.start_recording()
            
    def start_recording(self):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.output_file = str(Path.home() / f"interview_{timestamp}.mp3")
        
        sink = self.get_default_sink()
        monitor = f"{sink}.monitor"
        
        print(f"\nâ–¶ ÐÐ°Ñ‡Ð¸Ð½Ð°ÑŽ Ð·Ð°Ð¿Ð¸ÑÑŒ: {self.output_file}")
        print(f"  Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ð¹ Ð·Ð²ÑƒÐº: {monitor}")
        print(f"  ÐœÐ¸ÐºÑ€Ð¾Ñ„Ð¾Ð½: default")
        
        cmd = [
            "ffmpeg",
            "-f", "pulse", "-i", monitor,
            "-f", "pulse", "-i", "default",
            "-filter_complex", "amix=inputs=2:duration=longest",
            "-ac", "1",
            "-ar", "16000",
            "-codec:a", "libmp3lame",
            "-qscale:a", "4",
            "-y",
            self.output_file
        ]
        
        try:
            self.process = subprocess.Popen(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        except Exception as e:
            messagebox.showerror("ÐžÑˆÐ¸Ð±ÐºÐ°", f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð½Ð°Ñ‡Ð°Ñ‚ÑŒ Ð·Ð°Ð¿Ð¸ÑÑŒ:\n{e}")
            return
            
        self.meter = AudioMeter(self.update_meter)
        self.meter.start()
            
        self.recording = True
        self.start_time = time.time()
        
        self.status_var.set("ðŸ”´ Ð˜Ð´Ñ‘Ñ‚ Ð·Ð°Ð¿Ð¸ÑÑŒ...")
        self.record_btn.config(text="â¹ ÐžÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ")
        self.transcribe_file_btn.config(state=tk.DISABLED)
        self.file_var.set("")
        
        self.update_timer()
        
    def stop_recording(self):
        if self.meter:
            self.meter.stop()
            self.meter = None
        self.meter_level = 0
        self.draw_meter()
        
        if self.process:
            self.process.send_signal(signal.SIGINT)
            self.process.wait()
            self.process = None
            
        self.recording = False
        self.record_btn.config(text="âº ÐÐ°Ñ‡Ð°Ñ‚ÑŒ Ð·Ð°Ð¿Ð¸ÑÑŒ")
        self.transcribe_file_btn.config(state=tk.NORMAL)
        self.timer_var.set("00:00:00")
        
        elapsed = int(time.time() - self.start_time)
        print(f"\nâ¹ Ð—Ð°Ð¿Ð¸ÑÑŒ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð°. Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ: {elapsed // 60}:{elapsed % 60:02d}")
        
        if not self.output_file or not Path(self.output_file).exists():
            self.status_var.set("âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð¿Ð¸ÑÐ¸")
            print("âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: Ñ„Ð°Ð¹Ð» Ð½Ðµ ÑÐ¾Ð·Ð´Ð°Ð½")
            return
        
        mp3_size = Path(self.output_file).stat().st_size / (1024 * 1024)
        print(f"âœ“ MP3 ÑÐ¾Ð·Ð´Ð°Ð½: {mp3_size:.1f} MB")
            
        if self.transcribe_var.get():
            threading.Thread(target=self.transcribe_file, args=(self.output_file,), daemon=True).start()
        else:
            self.status_var.set("âœ… Ð“Ð¾Ñ‚Ð¾Ð²Ð¾!")
            self.file_var.set(f"ðŸ“ {Path(self.output_file).name} ({mp3_size:.1f} MB)")
            
        if not self.keep_audio_var.get() and not self.transcribe_var.get():
            os.remove(self.output_file)
            self.file_var.set("")
            
    def transcribe_existing_file(self):
        if self.transcribing:
            messagebox.showwarning("ÐŸÐ¾Ð´Ð¾Ð¶Ð´Ð¸Ñ‚Ðµ", "Ð¢Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ñ ÑƒÐ¶Ðµ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ÑÑ")
            return

        filepath = filedialog.askopenfilename(
            title="Ð’Ñ‹Ð±ÐµÑ€Ð¸ Ð°ÑƒÐ´Ð¸Ð¾Ñ„Ð°Ð¹Ð»",
            initialdir=Path.home(),
            filetypes=[
                ("ÐÑƒÐ´Ð¸Ð¾Ñ„Ð°Ð¹Ð»Ñ‹", "*.mp3 *.wav *.m4a *.ogg *.flac"),
                ("Ð’ÑÐµ Ñ„Ð°Ð¹Ð»Ñ‹", "*.*")
            ]
        )

        if filepath:
            threading.Thread(target=self.transcribe_file, args=(filepath,), daemon=True).start()

    def format_dialogue_to_text(self, dialogue_result):
        """Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð° Ð´Ð¸Ð°Ð»Ð¾Ð³Ð° Ð² Ñ‚ÐµÐºÑÑ‚."""
        if 'error' in dialogue_result:
            return f"ÐžÐ¨Ð˜Ð‘ÐšÐ: {dialogue_result['error']}"

        dialogue = dialogue_result.get('dialogue', [])
        language = dialogue_result.get('language', 'unknown')
        num_speakers = dialogue_result.get('num_speakers', 0)

        lines = []
        lines.append(f"Ð¯Ð·Ñ‹Ðº: {language}")
        lines.append(f"ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑÐ¿Ð¸ÐºÐµÑ€Ð¾Ð²: {num_speakers}")
        lines.append("=" * 60)
        lines.append("")

        for turn in dialogue:
            speaker = turn.get('speaker', 'UNKNOWN')
            text = turn.get('text', '')
            start = turn.get('start', 0)
            end = turn.get('end', 0)

            timestamp = f"[{int(start//60):02d}:{int(start%60):02d} - {int(end//60):02d}:{int(end%60):02d}]"
            lines.append(f"{speaker} {timestamp}:")
            lines.append(text)
            lines.append("")

        return "\n".join(lines)

    def transcribe_on_server(self, filepath):
        """ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ñ„Ð°Ð¹Ð»Ð° Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€ Ð´Ð»Ñ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ð¸."""
        runpod_key = os.environ.get('RUNPOD_API_KEY')

        if not runpod_key:
            raise ValueError("RUNPOD_API_KEY Ð½Ðµ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½ Ð² Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ.\n\nÐ”Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ Ð² ~/.bashrc:\nexport RUNPOD_API_KEY=\"Ð²Ð°Ñˆ_ÐºÐ»ÑŽÑ‡\"")

        # Ð§Ð¸Ñ‚Ð°ÐµÐ¼ Ñ„Ð°Ð¹Ð» Ð¸ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð² base64
        print(f"ðŸ“¤ ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€: {filepath}")
        file_size_mb = Path(filepath).stat().st_size / (1024 * 1024)
        print(f"   Ð Ð°Ð·Ð¼ÐµÑ€ Ñ„Ð°Ð¹Ð»Ð°: {file_size_mb:.1f} MB")

        self.root.after(0, lambda: self.status_var.set(f"ðŸ“¤ Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ñ„Ð°Ð¹Ð»Ð° ({file_size_mb:.1f} MB)..."))

        with open(filepath, 'rb') as f:
            audio_data = f.read()
            audio_base64 = base64.b64encode(audio_data).decode('utf-8')

        # ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
        lang = self.language_var.get()
        payload = {
            "input": {
                "audio_base64": audio_base64,
                "language": lang,
                "format": "dialogue"
            }
        }

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {runpod_key}"
        }

        print(f"   Ð¯Ð·Ñ‹Ðº: {lang}")
        print(f"   Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚: dialogue")
        print(f"   Ð”Ð¸Ð°Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ñ: Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½Ð° (HF_TOKEN Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€Ðµ)")

        # ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
        self.root.after(0, lambda: self.status_var.set("â³ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€Ðµ..."))
        print("ðŸ”„ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€Ðµ...")

        try:
            response = requests.post(
                self.runpod_endpoint,
                json=payload,
                headers=headers,
                timeout=600  # 10 Ð¼Ð¸Ð½ÑƒÑ‚ Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚
            )
            response.raise_for_status()
            result = response.json()

            # RunPod Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð² Ð¿Ð¾Ð»Ðµ "output"
            if 'output' in result:
                return result['output']
            elif 'id' in result:
                # ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ - Ð½ÑƒÐ¶Ð½Ð¾ Ð¾Ð¿Ñ€Ð¾ÑÐ¸Ñ‚ÑŒ ÑÑ‚Ð°Ñ‚ÑƒÑ
                job_id = result['id']
                return self._poll_runpod_result(job_id, runpod_key)
            else:
                raise ValueError(f"ÐÐµÐ¾Ð¶Ð¸Ð´Ð°Ð½Ð½Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ð¾Ñ‚Ð²ÐµÑ‚Ð°: {result}")

        except requests.Timeout:
            raise TimeoutError("ÐŸÑ€ÐµÐ²Ñ‹ÑˆÐµÐ½Ð¾ Ð²Ñ€ÐµÐ¼Ñ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¾Ñ‚ ÑÐµÑ€Ð²ÐµÑ€Ð°")
        except requests.RequestException as e:
            raise ValueError(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°: {str(e)}")

    def _poll_runpod_result(self, job_id, api_key):
        """ÐžÐ¿Ñ€Ð¾Ñ ÑÑ‚Ð°Ñ‚ÑƒÑÐ° Ð·Ð°Ð´Ð°Ñ‡Ð¸ RunPod."""
        status_url = f"{self.runpod_endpoint.rsplit('/', 1)[0]}/status/{job_id}"
        headers = {
            "Authorization": f"Bearer {api_key}"
        }

        print(f"â³ ÐžÐ¶Ð¸Ð´Ð°Ð½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð° (Job ID: {job_id})...")
        max_attempts = 120  # 10 Ð¼Ð¸Ð½ÑƒÑ‚ (120 * 5 ÑÐµÐºÑƒÐ½Ð´)
        attempt = 0

        while attempt < max_attempts:
            try:
                response = requests.get(status_url, headers=headers, timeout=30)
                response.raise_for_status()
                status_data = response.json()

                status = status_data.get('status')
                if status == 'COMPLETED':
                    return status_data.get('output')
                elif status == 'FAILED':
                    error = status_data.get('error', 'Unknown error')
                    raise ValueError(f"Ð—Ð°Ð´Ð°Ñ‡Ð° Ð·Ð°Ð²ÐµÑ€ÑˆÐ¸Ð»Ð°ÑÑŒ Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ¾Ð¹: {error}")
                elif status in ['IN_QUEUE', 'IN_PROGRESS']:
                    attempt += 1
                    time.sleep(5)
                    if attempt % 6 == 0:  # ÐšÐ°Ð¶Ð´Ñ‹Ðµ 30 ÑÐµÐºÑƒÐ½Ð´
                        print(f"   Ð¡Ñ‚Ð°Ñ‚ÑƒÑ: {status} ({attempt * 5}s)")
                else:
                    raise ValueError(f"ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑ: {status}")

            except requests.RequestException as e:
                raise ValueError(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð¿Ñ€Ð¾ÑÐµ ÑÑ‚Ð°Ñ‚ÑƒÑÐ°: {str(e)}")

        raise TimeoutError("ÐŸÑ€ÐµÐ²Ñ‹ÑˆÐµÐ½Ð¾ Ð²Ñ€ÐµÐ¼Ñ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð° Ð¾Ñ‚ ÑÐµÑ€Ð²ÐµÑ€Ð°")
    
    def transcribe_file(self, filepath):
        """Ð¢Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ñ Ñ„Ð°Ð¹Ð»Ð° Ñ‡ÐµÑ€ÐµÐ· CLI whisper Ð¸Ð»Ð¸ ÑÐµÑ€Ð²ÐµÑ€."""
        self.transcribing = True
        self.root.after(0, lambda: self.record_btn.config(state=tk.DISABLED))
        self.root.after(0, lambda: self.transcribe_file_btn.config(state=tk.DISABLED))
        self.root.after(0, lambda: self.status_var.set("â³ Ð¢Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ñ..."))

        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ
        try:
            duration_result = subprocess.run([
                "ffprobe", "-v", "error", "-show_entries", "format=duration",
                "-of", "default=noprint_wrappers=1:nokey=1", filepath
            ], capture_output=True, text=True)
            total_duration = float(duration_result.stdout.strip())
            dur_str = f"{int(total_duration // 60)}:{int(total_duration % 60):02d}"
        except:
            total_duration = 0
            dur_str = "??:??"

        lang = self.language_var.get()
        lang_name = "Ð ÑƒÑÑÐºÐ¸Ð¹" if lang == "ru" else "English"

        print(f"\nâ³ Ð¢Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ñ: {filepath}")
        print(f"   Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ: {dur_str}")
        print(f"   Ð¯Ð·Ñ‹Ðº: {lang_name}")

        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð»Ð¸ ÑÐµÑ€Ð²ÐµÑ€
        use_server = self.use_server_var.get()

        if use_server:
            print(f"   Ð ÐµÐ¶Ð¸Ð¼: â˜ï¸  Ð¡ÐµÑ€Ð²ÐµÑ€ (WhisperX + Ð´Ð¸Ð°Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ñ)")
            print("-" * 40)
            self._transcribe_on_server_wrapper(filepath)
        else:
            model = self.model_var.get()
            print(f"   ÐœÐ¾Ð´ÐµÐ»ÑŒ: {model}")
            print(f"   Ð ÐµÐ¶Ð¸Ð¼: ðŸ’» Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾ (Whisper)")
            print("-" * 40)
            self._transcribe_locally(filepath, lang, model)

    def _transcribe_on_server_wrapper(self, filepath):
        """ÐžÐ±ÐµÑ€Ñ‚ÐºÐ° Ð´Ð»Ñ ÑÐµÑ€Ð²ÐµÑ€Ð½Ð¾Ð¹ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ð¸."""
        try:
            start_time = time.time()
            result = self.transcribe_on_server(filepath)

            elapsed = time.time() - start_time
            print(f"\nâœ… Ð—Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾ Ð·Ð° {int(elapsed // 60)}:{int(elapsed % 60):02d}")

            # Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
            text_content = self.format_dialogue_to_text(result)

            # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð² Ñ„Ð°Ð¹Ð»
            txt_file = filepath.rsplit(".", 1)[0] + ".txt"
            with open(txt_file, 'w', encoding='utf-8') as f:
                f.write(text_content)

            txt_size = Path(txt_file).stat().st_size / 1024
            print(f"âœ“ Ð¢Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ‚: {txt_file} ({txt_size:.1f} KB)")

            num_speakers = result.get('num_speakers', 0)
            self.root.after(0, lambda: self.status_var.set(f"âœ… Ð¢Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð° ({num_speakers} ÑÐ¿Ð¸ÐºÐµÑ€Ð¾Ð²)"))
            self.root.after(0, lambda: self.file_var.set(f"ðŸ“„ {Path(txt_file).name}"))

            if not self.keep_audio_var.get() and filepath == self.output_file:
                os.remove(filepath)
                print("âœ“ ÐÑƒÐ´Ð¸Ð¾Ñ„Ð°Ð¹Ð» ÑƒÐ´Ð°Ð»Ñ‘Ð½")

        except Exception as e:
            print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: {e}")
            self.root.after(0, lambda: self.status_var.set(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: {str(e)[:30]}"))
            self.root.after(0, lambda: messagebox.showerror("ÐžÑˆÐ¸Ð±ÐºÐ° Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ð¸", str(e)))
        finally:
            self.transcribing = False
            self.root.after(0, lambda: self.record_btn.config(state=tk.NORMAL))
            self.root.after(0, lambda: self.transcribe_file_btn.config(state=tk.NORMAL))
            print("-" * 40)

    def _transcribe_locally(self, filepath, lang, model):
        """Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ð°Ñ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ñ Ñ‡ÐµÑ€ÐµÐ· CLI whisper."""
        
        try:
            check = subprocess.run(["whisper", "--help"], capture_output=True)
            if check.returncode != 0:
                raise FileNotFoundError("whisper not found")
            
            output_dir = str(Path(filepath).parent)
            start_time = time.time()
            
            process = subprocess.Popen([
                "whisper", filepath,
                "--model", model,
                "--language", lang,
                "--output_format", "txt",
                "--output_dir", output_dir
            ], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1)
            
            for line in process.stdout:
                line = line.strip()
                if line:
                    print(line)
            
            process.wait()
            
            elapsed = time.time() - start_time
            print(f"\nÐ—Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾ Ð·Ð° {int(elapsed // 60)}:{int(elapsed % 60):02d}")
            
            txt_file = filepath.rsplit(".", 1)[0] + ".txt"
            if Path(txt_file).exists():
                txt_size = Path(txt_file).stat().st_size / 1024
                print(f"âœ“ Ð¢Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ‚: {txt_file} ({txt_size:.1f} KB)")
                
                self.root.after(0, lambda: self.status_var.set("âœ… Ð¢Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°"))
                self.root.after(0, lambda: self.file_var.set(f"ðŸ“„ {Path(txt_file).name}"))
                
                if not self.keep_audio_var.get() and filepath == self.output_file:
                    os.remove(filepath)
                    print("âœ“ ÐÑƒÐ´Ð¸Ð¾Ñ„Ð°Ð¹Ð» ÑƒÐ´Ð°Ð»Ñ‘Ð½")
            else:
                print("âš ï¸ Ð¤Ð°Ð¹Ð» Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ‚Ð° Ð½Ðµ ÑÐ¾Ð·Ð´Ð°Ð½")
                self.root.after(0, lambda: self.status_var.set("âš ï¸ Ð¢Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ñ Ð½Ðµ ÑƒÐ´Ð°Ð»Ð°ÑÑŒ"))
            
        except FileNotFoundError:
            print("âŒ Whisper Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð² PATH!")
            print("   Ð£Ð±ÐµÐ´Ð¸ÑÑŒ Ñ‡Ñ‚Ð¾ /media/data/pipx/bin Ð² PATH")
            self.root.after(0, lambda: messagebox.showerror(
                "Whisper Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½",
                "Whisper Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð² PATH.\n\nÐ”Ð¾Ð±Ð°Ð²ÑŒ Ð² ~/.bashrc:\nexport PATH=\"/media/data/pipx/bin:$PATH\"\n\nÐ˜ Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÑ‚Ð¸ Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ð°Ð»."
            ))
            self.root.after(0, lambda: self.status_var.set("âŒ Whisper Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½"))
        except Exception as e:
            print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: {e}")
            self.root.after(0, lambda: self.status_var.set(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: {str(e)[:30]}"))
        finally:
            self.transcribing = False
            self.root.after(0, lambda: self.record_btn.config(state=tk.NORMAL))
            self.root.after(0, lambda: self.transcribe_file_btn.config(state=tk.NORMAL))
            print("-" * 40)
            
    def update_timer(self):
        if self.recording:
            elapsed = int(time.time() - self.start_time)
            h, m, s = elapsed // 3600, (elapsed % 3600) // 60, elapsed % 60
            self.timer_var.set(f"{h:02d}:{m:02d}:{s:02d}")
            self.root.after(1000, self.update_timer)
            
    def open_folder(self):
        subprocess.run(["xdg-open", str(Path.home())])
        
    def run(self):
        def on_close():
            if self.recording:
                self.stop_recording()
            self.root.quit()
            
        self.root.protocol("WM_DELETE_WINDOW", on_close)
        self.root.mainloop()


if __name__ == "__main__":
    app = InterviewRecorder()
    app.run()
